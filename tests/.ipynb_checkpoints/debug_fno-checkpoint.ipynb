{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051fe4bf-cb69-4dde-a560-6bd27592d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: 모듈 import를 위한 경로 설정\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))  # shared, models 디렉토리 접근 가능하도록 경로 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c33f512-7bb2-485b-92b8-942cf8edfabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch version: 2.6.0+cu124\n",
      "🚀 GPU available: True\n",
      "🧠 GPU name: Quadro RTX 5000\n",
      "💾 Total memory: 15.73 GiB\n",
      "📦 Reserved memory: 0.00 GiB\n",
      "📈 Allocated memory: 0.00 GiB\n",
      "🟢 Free memory in reserved: 0.00 GiB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 환경 확인\n",
    "import torch\n",
    "\n",
    "print(f\"✅ PyTorch version: {torch.__version__}\")\n",
    "print(f\"🚀 GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"🧠 GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"💾 Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"📦 Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"📈 Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"🟢 Free memory in reserved: {free_memory:.2f} GiB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2533429-64ef-4156-90bd-a80eff88e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:02:56,755 | INFO | data_loader | 🔍 Initializing dataset with 9 file pairs.\n",
      "2025-06-13 14:02:56,775 | INFO | data_loader | 📦 Total samples across all files: 884736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample loaded: input shape = torch.Size([2, 1, 60, 60, 60]), output shape = torch.Size([2, 1, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 데이터셋 로딩\n",
    "from torch.utils.data import DataLoader\n",
    "from shared.data_loader import HDF5Dataset\n",
    "import os\n",
    "\n",
    "input_dir = \"/caefs/data/IllustrisTNG/subcube/input\"\n",
    "output_dir = \"/caefs/data/IllustrisTNG/subcube/output\"\n",
    "\n",
    "input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".h5\")])\n",
    "output_files = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".h5\")])\n",
    "\n",
    "dataset = HDF5Dataset(input_files, output_files)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "print(f\"✅ Sample loaded: input shape = {x.shape}, output shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb82d3e3-6a0f-48ad-8349-a3c5156be53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:36,832 | INFO | models.fno.model | ✅ FNO model initialized successfully.\n",
      "2025-06-13 14:05:36,939 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([2, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:36,940 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:36,944 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:36,953 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([2, 4, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FNO model loaded and set to training mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:37,277 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:37,280 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:37,283 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:37,286 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:37,633 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([2, 1, 60, 60, 60])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "FNO                                      [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "├─Linear: 1-1                            [432000, 4]               [432000, 64]              320                       --\n",
       "├─Linear: 1-2                            [432000, 64]              [432000, 128]             8,320                     --\n",
       "├─ModuleList: 1-3                        --                        --                        --                        --\n",
       "│    └─SpectralConvolution: 2-1          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "│    └─SpectralConvolution: 2-2          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "│    └─SpectralConvolution: 2-3          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "│    └─SpectralConvolution: 2-4          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "├─Linear: 1-4                            [2, 60, 60, 60, 128]      [2, 60, 60, 60, 128]      16,512                    --\n",
       "├─GELU: 1-5                              [2, 60, 60, 60, 128]      [2, 60, 60, 60, 128]      --                        --\n",
       "├─Linear: 1-6                            [2, 60, 60, 60, 128]      [2, 60, 60, 60, 1]        129                       --\n",
       "============================================================================================================================================\n",
       "Total params: 307,393\n",
       "Trainable params: 307,393\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.73\n",
       "============================================================================================================================================\n",
       "Input size (MB): 1.73\n",
       "Forward/backward pass size (MB): 1109.38\n",
       "Params size (MB): 0.10\n",
       "Estimated Total Size (MB): 1111.21\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.fno.model import FNO\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# FNO 모델 초기화\n",
    "model = FNO(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    modes1=16,\n",
    "    modes2=16,\n",
    "    modes3=16,\n",
    "    width=128,\n",
    "    lifting_channels=64,\n",
    "    add_grid=True\n",
    ").to(device)\n",
    "\n",
    "model.train()\n",
    "print(\"✅ FNO model loaded and set to training mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac286a7-e717-4a49-bf87-322ec2af49df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:37,646 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([2, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:37,647 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:37,648 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:37,649 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([2, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:37,651 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:37,654 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:37,656 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:37,658 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:37,659 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([2, 1, 60, 60, 60])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "FNO                                      [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "├─Linear: 1-1                            [432000, 4]               [432000, 64]              320                       --\n",
       "├─Linear: 1-2                            [432000, 64]              [432000, 128]             8,320                     --\n",
       "├─ModuleList: 1-3                        --                        --                        --                        --\n",
       "│    └─SpectralConvolution: 2-1          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "│    └─SpectralConvolution: 2-2          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "│    └─SpectralConvolution: 2-3          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "│    └─SpectralConvolution: 2-4          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "├─Linear: 1-4                            [2, 60, 60, 60, 128]      [2, 60, 60, 60, 128]      16,512                    --\n",
       "├─GELU: 1-5                              [2, 60, 60, 60, 128]      [2, 60, 60, 60, 128]      --                        --\n",
       "├─Linear: 1-6                            [2, 60, 60, 60, 128]      [2, 60, 60, 60, 1]        129                       --\n",
       "============================================================================================================================================\n",
       "Total params: 307,393\n",
       "Trainable params: 307,393\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.73\n",
       "============================================================================================================================================\n",
       "Input size (MB): 1.73\n",
       "Forward/backward pass size (MB): 1109.38\n",
       "Params size (MB): 0.10\n",
       "Estimated Total Size (MB): 1111.21\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(2, 1, 60, 60, 60),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20205bcd-72cc-4c2f-a10b-54ec5689f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:38,504 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([32, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:38,505 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:38,506 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:38,506 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([32, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:39,059 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([16, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:39,059 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:39,060 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:39,060 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([16, 4, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed with batch_size=32: CUDA out of memory. Tried to allocate 6.59 GiB. GPU 0 has a total capacity of 15.73 GiB of which 5.54 GiB is free. Process 12502 has 26.06 MiB memory in use. Including non-PyTorch memory, this process has 10.16 GiB memory in use. Of the allocated memory 9.95 GiB is allocated by PyTorch, and 63.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:39,454 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([8, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:39,455 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:39,456 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:39,456 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([8, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:39,538 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:39,542 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:39,545 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:39,549 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:39,550 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([8, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed with batch_size=16: CUDA out of memory. Tried to allocate 3.30 GiB. GPU 0 has a total capacity of 15.73 GiB of which 2.24 GiB is free. Process 12502 has 26.06 MiB memory in use. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "✅ Success with batch_size=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:40,339 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:40,340 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:40,341 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:40,341 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:40,388 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:40,392 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:40,395 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:40,398 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:40,399 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with batch_size=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:40,953 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([2, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:40,954 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:40,955 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:40,955 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([2, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:40,957 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:40,959 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:40,962 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:40,964 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:40,965 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([2, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with batch_size=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:05:41,429 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([1, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:41,430 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:41,430 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:41,431 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([1, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:41,450 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:41,454 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:41,458 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:41,461 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:41,462 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([1, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with batch_size=1\n"
     ]
    }
   ],
   "source": [
    "def test_batch_size(batch_size):\n",
    "    try:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _ = model(x)\n",
    "                print(f\"✅ Success with batch_size={batch_size}\")\n",
    "                break\n",
    "    except RuntimeError as e:\n",
    "        print(f\"❌ Failed with batch_size={batch_size}: {str(e).splitlines()[0]}\")\n",
    "\n",
    "for bs in [32, 16, 8, 4, 2, 1]:\n",
    "    test_batch_size(bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ac54ce-3ade-4ecd-9994-9cf5823959ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MSE Loss on sample batch: 26.8519\n"
     ]
    }
   ],
   "source": [
    "from shared.losses import mse_loss, spectral_loss\n",
    "\n",
    "loss_val = mse_loss(x.to(device), y.to(device))\n",
    "print(f\"✅ MSE Loss on sample batch: {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3834fd-c938-4697-80ce-c311fc22d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimizer and LR scheduler initialized.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(\"✅ Optimizer and LR scheduler initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de346c0-7eb5-4715-9a9d-149762f80ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/221184 [00:00<?, ?it/s]2025-06-13 14:05:44,961 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:44,966 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:44,967 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:44,968 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:44,973 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:44,976 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:44,979 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:44,982 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:44,984 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 1/221184 [00:02<129:25:44,  2.11s/it]2025-06-13 14:05:46,690 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:46,693 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:46,694 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:46,694 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:46,697 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:46,700 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:46,702 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:46,704 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:46,705 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 2/221184 [00:03<113:41:17,  1.85s/it]2025-06-13 14:05:48,371 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:48,372 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:48,374 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:48,375 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:48,379 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:48,383 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:48,386 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:48,389 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:48,390 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 3/221184 [00:05<108:50:04,  1.77s/it]2025-06-13 14:05:50,211 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:50,212 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:50,214 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:50,215 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:50,221 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:50,225 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:50,228 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:50,232 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:50,233 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 4/221184 [00:07<110:34:52,  1.80s/it]2025-06-13 14:05:51,940 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:51,942 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:51,943 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:51,944 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:51,950 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:51,955 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:51,959 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:51,963 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:51,964 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 5/221184 [00:09<109:05:56,  1.78s/it]2025-06-13 14:05:53,558 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:53,559 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:53,560 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:53,561 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:53,566 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:53,570 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:53,573 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:53,577 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:53,578 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 6/221184 [00:10<105:39:33,  1.72s/it]2025-06-13 14:05:55,122 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:55,123 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:55,124 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:55,125 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:55,130 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:55,134 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:55,137 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:55,140 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:55,141 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n",
      "Epoch 1:   0%|          | 7/221184 [00:12<102:37:20,  1.67s/it]2025-06-13 14:05:56,977 | INFO | models.fno.model | 🚀 FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-13 14:05:56,978 | INFO | models.fno.model | 🌐 Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-13 14:05:56,979 | INFO | models.fno.model | ✅ Coordinate grid generated.\n",
      "2025-06-13 14:05:56,980 | INFO | models.fno.model | 🔗 Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-13 14:05:56,984 | INFO | models.fno.model | 🔁 Passed through Fourier layer 1/4\n",
      "2025-06-13 14:05:56,987 | INFO | models.fno.model | 🔁 Passed through Fourier layer 2/4\n",
      "2025-06-13 14:05:56,991 | INFO | models.fno.model | 🔁 Passed through Fourier layer 3/4\n",
      "2025-06-13 14:05:56,993 | INFO | models.fno.model | 🔁 Passed through Fourier layer 4/4\n",
      "2025-06-13 14:05:56,995 | INFO | models.fno.model | ✅ Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "n_batch = 10\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        if i >= n_batch:\n",
    "            break\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = mse_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"📉 Epoch {epoch+1} Loss: {total_loss / n_batch:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a1fec-7c5b-4035-8ead-0697b70b60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"fno_test_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"✅ FNO model saved to {save_path}\")\n",
    "\n",
    "state_dict = torch.load(save_path, map_location='cpu')\n",
    "print(f\"🔍 저장된 키 개수: {len(state_dict)}\")\n",
    "print(\"예시 키:\", list(state_dict.keys())[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
