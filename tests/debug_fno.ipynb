{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051fe4bf-cb69-4dde-a560-6bd27592d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))  # shared, models ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ê²½ë¡œ ì¶”ê°€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c33f512-7bb2-485b-92b8-942cf8edfabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch version: 2.6.0+cu124\n",
      "ğŸš€ GPU available: True\n",
      "ğŸ§  GPU name: Quadro RTX 5000\n",
      "ğŸ’¾ Total memory: 15.73 GiB\n",
      "ğŸ“¦ Reserved memory: 0.00 GiB\n",
      "ğŸ“ˆ Allocated memory: 0.00 GiB\n",
      "ğŸŸ¢ Free memory in reserved: 0.00 GiB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: í™˜ê²½ í™•ì¸\n",
    "import torch\n",
    "\n",
    "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸš€ GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"ğŸ§  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"ğŸ’¾ Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“¦ Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“ˆ Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"ğŸŸ¢ Free memory in reserved: {free_memory:.2f} GiB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2533429-64ef-4156-90bd-a80eff88e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 20:46:57,291 | INFO | data_loader | ğŸ” Initializing dataset with 12 file pairs.\n",
      "2025-07-30 20:46:57,315 | INFO | data_loader | ğŸ“¦ Total samples across all files: 110592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample loaded: input shape = torch.Size([2, 1, 60, 60, 60]), output shape = torch.Size([2, 1, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ë°ì´í„°ì…‹ ë¡œë”©\n",
    "from torch.utils.data import DataLoader\n",
    "from shared.data_loader import HDF5Dataset\n",
    "import os\n",
    "\n",
    "input_dir = \"/caefs/data/IllustrisTNG/subcube/input\"\n",
    "output_dir = \"/caefs/data/IllustrisTNG/subcube/output\"\n",
    "\n",
    "input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".h5\")])\n",
    "output_files = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".h5\")])\n",
    "\n",
    "dataset = HDF5Dataset(input_files, output_files)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "print(f\"âœ… Sample loaded: input shape = {x.shape}, output shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82d3e3-6a0f-48ad-8349-a3c5156be53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fno.model import FNO\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# FNO ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = FNO(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    modes1=32,\n",
    "    modes2=32,\n",
    "    modes3=32,\n",
    "    width=128,\n",
    "    lifting_channels=128,\n",
    "    add_grid=True,\n",
    "    activation=nn.ReLU\n",
    ").to(device)\n",
    "\n",
    "model.train()\n",
    "print(\"âœ… FNO model loaded and set to training mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac286a7-e717-4a49-bf87-322ec2af49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(2, 1, 60, 60, 60),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20205bcd-72cc-4c2f-a10b-54ec5689f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_size(batch_size):\n",
    "    try:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _ = model(x)\n",
    "                print(f\"âœ… Success with batch_size={batch_size}\")\n",
    "                break\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âŒ Failed with batch_size={batch_size}: {str(e).splitlines()[0]}\")\n",
    "\n",
    "for bs in [32, 16, 8, 4, 2, 1]:\n",
    "    test_batch_size(bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac54ce-3ade-4ecd-9994-9cf5823959ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.losses import mse_loss, spectral_loss\n",
    "\n",
    "loss_val = mse_loss(x.to(device), y.to(device))\n",
    "print(f\"âœ… MSE Loss on sample batch: {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3834fd-c938-4697-80ce-c311fc22d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(\"âœ… Optimizer and LR scheduler initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de346c0-7eb5-4715-9a9d-149762f80ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "n_batch = 10\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        if i >= n_batch:\n",
    "            break\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = mse_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"ğŸ“‰ Epoch {epoch+1} Loss: {total_loss / n_batch:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f34bd0-297a-47bb-99f5-746fbd733181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Trainer ì„¤ì • (ë””ë²„ê¹…ìš©)\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=True,\n",
    "    detect_anomaly=True,\n",
    "    logger=CSVLogger(\"logs/debug_fno\", name=\"fno_test\"),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=2, mode=\"min\", verbose=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a1fec-7c5b-4035-8ead-0697b70b60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"fno_test_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"âœ… FNO model saved to {save_path}\")\n",
    "\n",
    "state_dict = torch.load(save_path, map_location='cpu')\n",
    "print(f\"ğŸ” ì €ì¥ëœ í‚¤ ê°œìˆ˜: {len(state_dict)}\")\n",
    "print(\"ì˜ˆì‹œ í‚¤:\", list(state_dict.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a209466-38d9-4d97-aef8-019b6cbb0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_sample, target_sample = next(iter(loader))\n",
    "    input_sample, target_sample = input_sample.to(device), target_sample.to(device)\n",
    "    pred_sample = model(input_sample)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149884c-3ab0-4ae4-b9f7-bb28d607320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ì˜ˆì‹œ: input = [B, 1, D, H, W] ì¤‘ì—ì„œ B=0, D=30ì¸ 2D ìŠ¬ë¼ì´ìŠ¤\n",
    "input_slice = inputs[0, 0, 30].detach().cpu().numpy()\n",
    "target_slice = targets[0, 0, 30].detach().cpu().numpy()\n",
    "pred_slice = outputs[0, 0, 30].detach().cpu().numpy()\n",
    "\n",
    "# âœ… log-transform (0ì„ í”¼í•˜ê¸° ìœ„í•´ log(1 + x) ì‚¬ìš©)\n",
    "input_log = np.log10(1 + input_slice)\n",
    "\n",
    "# ğŸ“Š ì‹œê°í™”\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axs[0].imshow(input_log, cmap='viridis')\n",
    "axs[0].set_title('Input (log10)')\n",
    "\n",
    "axs[1].imshow(target_slice, cmap='viridis')\n",
    "axs[1].set_title('Target')\n",
    "\n",
    "axs[2].imshow(pred_slice, cmap='viridis')\n",
    "axs[2].set_title('Prediction')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
