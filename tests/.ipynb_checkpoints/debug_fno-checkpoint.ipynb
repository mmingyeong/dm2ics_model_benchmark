{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051fe4bf-cb69-4dde-a560-6bd27592d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))  # shared, models ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ê²½ë¡œ ì¶”ê°€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c33f512-7bb2-485b-92b8-942cf8edfabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch version: 2.6.0+cu124\n",
      "ğŸš€ GPU available: True\n",
      "ğŸ§  GPU name: Quadro RTX 5000\n",
      "ğŸ’¾ Total memory: 15.73 GiB\n",
      "ğŸ“¦ Reserved memory: 0.00 GiB\n",
      "ğŸ“ˆ Allocated memory: 0.00 GiB\n",
      "ğŸŸ¢ Free memory in reserved: 0.00 GiB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: í™˜ê²½ í™•ì¸\n",
    "import torch\n",
    "\n",
    "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸš€ GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"ğŸ§  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"ğŸ’¾ Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“¦ Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“ˆ Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"ğŸŸ¢ Free memory in reserved: {free_memory:.2f} GiB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2533429-64ef-4156-90bd-a80eff88e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:18:22,442 | INFO | data_loader | ğŸ” Initializing dataset with 12 file pairs.\n",
      "2025-06-17 10:18:22,468 | INFO | data_loader | ğŸ“¦ Total samples across all files: 110592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample loaded: input shape = torch.Size([2, 1, 60, 60, 60]), output shape = torch.Size([2, 1, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ë°ì´í„°ì…‹ ë¡œë”©\n",
    "from torch.utils.data import DataLoader\n",
    "from shared.data_loader import HDF5Dataset\n",
    "import os\n",
    "\n",
    "input_dir = \"/caefs/data/IllustrisTNG/subcube/input\"\n",
    "output_dir = \"/caefs/data/IllustrisTNG/subcube/output\"\n",
    "\n",
    "input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".h5\")])\n",
    "output_files = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".h5\")])\n",
    "\n",
    "dataset = HDF5Dataset(input_files, output_files)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "print(f\"âœ… Sample loaded: input shape = {x.shape}, output shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb82d3e3-6a0f-48ad-8349-a3c5156be53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:20:59,963 | INFO | models.fno.model | âœ… FNO model initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FNO model loaded and set to training mode.\n"
     ]
    }
   ],
   "source": [
    "from models.fno.model import FNO\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# FNO ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = FNO(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    modes1=32,\n",
    "    modes2=32,\n",
    "    modes3=32,\n",
    "    width=128,\n",
    "    lifting_channels=128,\n",
    "    add_grid=True,\n",
    "    activation=nn.ReLU\n",
    ").to(device)\n",
    "\n",
    "model.train()\n",
    "print(\"âœ… FNO model loaded and set to training mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac286a7-e717-4a49-bf87-322ec2af49df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:21:00,073 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([2, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:00,073 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:00,078 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:00,087 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([2, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:00,271 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 1/4\n",
      "2025-06-17 10:21:00,273 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 2/4\n",
      "2025-06-17 10:21:00,275 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 3/4\n",
      "2025-06-17 10:21:00,278 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 4/4\n",
      "2025-06-17 10:21:00,624 | INFO | models.fno.model | âœ… Forward pass completed. Output shape: torch.Size([2, 1, 60, 60, 60])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "FNO                                      [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "â”œâ”€Linear: 1-1                            [432000, 4]               [432000, 64]              320                       --\n",
       "â”œâ”€Linear: 1-2                            [432000, 64]              [432000, 128]             8,320                     --\n",
       "â”œâ”€ModuleList: 1-3                        --                        --                        --                        --\n",
       "â”‚    â””â”€SpectralConvolution: 2-1          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "â”‚    â””â”€SpectralConvolution: 2-2          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "â”‚    â””â”€SpectralConvolution: 2-3          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "â”‚    â””â”€SpectralConvolution: 2-4          [2, 128, 60, 60, 60]      [2, 128, 60, 60, 60]      70,528                    --\n",
       "â”œâ”€Linear: 1-4                            [2, 60, 60, 60, 128]      [2, 60, 60, 60, 128]      16,512                    --\n",
       "â”œâ”€Linear: 1-5                            [2, 60, 60, 60, 128]      [2, 60, 60, 60, 1]        129                       --\n",
       "============================================================================================================================================\n",
       "Total params: 307,393\n",
       "Trainable params: 307,393\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.73\n",
       "============================================================================================================================================\n",
       "Input size (MB): 1.73\n",
       "Forward/backward pass size (MB): 1109.38\n",
       "Params size (MB): 0.10\n",
       "Estimated Total Size (MB): 1111.21\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(2, 1, 60, 60, 60),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c932786-1525-4b31-bc13-1af777b45baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20205bcd-72cc-4c2f-a10b-54ec5689f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:21:00,779 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([32, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:00,780 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:00,781 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:00,781 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([32, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:01,294 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([16, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:01,295 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:01,296 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:01,296 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([16, 4, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed with batch_size=32: CUDA out of memory. Tried to allocate 6.59 GiB. GPU 0 has a total capacity of 15.73 GiB of which 504.50 MiB is free. Process 12502 has 26.06 MiB memory in use. Process 133015 has 5.05 GiB memory in use. Including non-PyTorch memory, this process has 10.16 GiB memory in use. Of the allocated memory 9.95 GiB is allocated by PyTorch, and 63.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:21:01,669 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([8, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:01,670 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:01,670 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:01,671 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([8, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:01,751 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 1/4\n",
      "2025-06-17 10:21:01,753 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 2/4\n",
      "2025-06-17 10:21:01,755 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 3/4\n",
      "2025-06-17 10:21:01,757 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 4/4\n",
      "2025-06-17 10:21:01,758 | INFO | models.fno.model | âœ… Forward pass completed. Output shape: torch.Size([8, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed with batch_size=16: CUDA out of memory. Tried to allocate 3.30 GiB. GPU 0 has a total capacity of 15.73 GiB of which 504.50 MiB is free. Process 12502 has 26.06 MiB memory in use. Process 133015 has 5.05 GiB memory in use. Including non-PyTorch memory, this process has 10.16 GiB memory in use. Of the allocated memory 8.28 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "âœ… Success with batch_size=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:21:02,554 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:02,555 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:02,556 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:02,556 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:02,601 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 1/4\n",
      "2025-06-17 10:21:02,604 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 2/4\n",
      "2025-06-17 10:21:02,606 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 3/4\n",
      "2025-06-17 10:21:02,608 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 4/4\n",
      "2025-06-17 10:21:02,609 | INFO | models.fno.model | âœ… Forward pass completed. Output shape: torch.Size([4, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Success with batch_size=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:21:03,166 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([2, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:03,167 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:03,168 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:03,168 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([2, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:03,171 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 1/4\n",
      "2025-06-17 10:21:03,173 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 2/4\n",
      "2025-06-17 10:21:03,175 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 3/4\n",
      "2025-06-17 10:21:03,177 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 4/4\n",
      "2025-06-17 10:21:03,178 | INFO | models.fno.model | âœ… Forward pass completed. Output shape: torch.Size([2, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Success with batch_size=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:21:03,640 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([1, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:03,641 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:03,642 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:03,642 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([1, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:03,659 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 1/4\n",
      "2025-06-17 10:21:03,661 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 2/4\n",
      "2025-06-17 10:21:03,663 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 3/4\n",
      "2025-06-17 10:21:03,666 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 4/4\n",
      "2025-06-17 10:21:03,667 | INFO | models.fno.model | âœ… Forward pass completed. Output shape: torch.Size([1, 1, 60, 60, 60])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Success with batch_size=1\n"
     ]
    }
   ],
   "source": [
    "def test_batch_size(batch_size):\n",
    "    try:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _ = model(x)\n",
    "                print(f\"âœ… Success with batch_size={batch_size}\")\n",
    "                break\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âŒ Failed with batch_size={batch_size}: {str(e).splitlines()[0]}\")\n",
    "\n",
    "for bs in [32, 16, 8, 4, 2, 1]:\n",
    "    test_batch_size(bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ac54ce-3ade-4ecd-9994-9cf5823959ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MSE Loss on sample batch: 16.1741\n"
     ]
    }
   ],
   "source": [
    "from shared.losses import mse_loss, spectral_loss\n",
    "\n",
    "loss_val = mse_loss(x.to(device), y.to(device))\n",
    "print(f\"âœ… MSE Loss on sample batch: {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3834fd-c938-4697-80ce-c311fc22d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Optimizer and LR scheduler initialized.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(\"âœ… Optimizer and LR scheduler initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de346c0-7eb5-4715-9a9d-149762f80ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/27648 [00:00<?, ?it/s]2025-06-17 10:21:06,769 | INFO | models.fno.model | ğŸš€ FNO forward pass started. Input shape: torch.Size([4, 1, 60, 60, 60])\n",
      "2025-06-17 10:21:06,770 | INFO | models.fno.model | ğŸŒ Generating coordinate grid with shape: [60, 60, 60]\n",
      "2025-06-17 10:21:06,771 | INFO | models.fno.model | âœ… Coordinate grid generated.\n",
      "2025-06-17 10:21:06,772 | INFO | models.fno.model | ğŸ”— Added grid to input. New shape: torch.Size([4, 4, 60, 60, 60])\n",
      "2025-06-17 10:21:06,778 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 1/4\n",
      "2025-06-17 10:21:06,783 | INFO | models.fno.model | ğŸ” Passed through Fourier layer 2/4\n",
      "Epoch 1:   0%|          | 0/27648 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 844.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 504.50 MiB is free. Process 12502 has 26.06 MiB memory in use. Process 133015 has 5.05 GiB memory in use. Including non-PyTorch memory, this process has 10.16 GiB memory in use. Of the allocated memory 8.57 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m inputs, targets = inputs.to(device), targets.to(device)\n\u001b[32m     13\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss = mse_loss(outputs, targets)\n\u001b[32m     16\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/2023.03/envs/py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/2023.03/envs/py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/caefs/user/mmingyeong/_dm2ics_model_benchmark/dm2ics_model_benchmark/models/fno/model.py:137\u001b[39m, in \u001b[36mFNO.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Fourier layers\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.fourier_blocks):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ” Passed through Fourier layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.fourier_blocks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Projection\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/2023.03/envs/py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/2023.03/envs/py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/caefs/user/mmingyeong/_dm2ics_model_benchmark/dm2ics_model_benchmark/models/fno/layers/spectral_convolution.py:254\u001b[39m, in \u001b[36mSpectralConvolution.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    247\u001b[39m     out_ft_real, out_ft_imag = \u001b[38;5;28mself\u001b[39m.mix_weights(\n\u001b[32m    248\u001b[39m         out_ft_real, out_ft_imag, x_ft_real, x_ft_imag,\n\u001b[32m    249\u001b[39m         tl.tt_to_tensor(\u001b[38;5;28mself\u001b[39m.factors_tt_real),\n\u001b[32m    250\u001b[39m         tl.tt_to_tensor(\u001b[38;5;28mself\u001b[39m.factors_tt_imag)\n\u001b[32m    251\u001b[39m     )\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Combine real and imaginary parts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m out_ft = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_ft_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_ft_imag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Apply IFFT to return to spatial domain\u001b[39;00m\n\u001b[32m    257\u001b[39m out = torch.fft.ifftn(out_ft, dim=\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(-\u001b[38;5;28mself\u001b[39m.dim, \u001b[32m0\u001b[39m)), s=sizes, norm=\u001b[33m'\u001b[39m\u001b[33mortho\u001b[39m\u001b[33m'\u001b[39m).real\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 844.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 504.50 MiB is free. Process 12502 has 26.06 MiB memory in use. Process 133015 has 5.05 GiB memory in use. Including non-PyTorch memory, this process has 10.16 GiB memory in use. Of the allocated memory 8.57 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "n_batch = 10\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        if i >= n_batch:\n",
    "            break\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = mse_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"ğŸ“‰ Epoch {epoch+1} Loss: {total_loss / n_batch:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f34bd0-297a-47bb-99f5-746fbd733181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Trainer ì„¤ì • (ë””ë²„ê¹…ìš©)\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=True,\n",
    "    detect_anomaly=True,\n",
    "    logger=CSVLogger(\"logs/debug_fno\", name=\"fno_test\"),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=2, mode=\"min\", verbose=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a1fec-7c5b-4035-8ead-0697b70b60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"fno_test_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"âœ… FNO model saved to {save_path}\")\n",
    "\n",
    "state_dict = torch.load(save_path, map_location='cpu')\n",
    "print(f\"ğŸ” ì €ì¥ëœ í‚¤ ê°œìˆ˜: {len(state_dict)}\")\n",
    "print(\"ì˜ˆì‹œ í‚¤:\", list(state_dict.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a209466-38d9-4d97-aef8-019b6cbb0d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
