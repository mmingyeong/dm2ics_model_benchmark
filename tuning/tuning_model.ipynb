{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa055be-ace8-42cb-96f9-3bc8adfcc710",
   "metadata": {},
   "source": [
    "# π”§ Hyperparameter Tuning Pipeline\n",
    "\n",
    "1. [ ] μ •μν•  ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •\n",
    "   - μ: learning rate, batch size, weight decay, dropout rate, model depth λ“±\n",
    "\n",
    "2. [ ] κ²€μƒ‰ κ³µκ°„(Search Space) μ •μ\n",
    "   - grid search, random search, λλ” optuna λ“±μΌλ΅ λ²”μ„ μ„¤μ •\n",
    "\n",
    "3. [ ] μ‹¤ν— λ°λ³µ κµ¬μ΅° κµ¬ν„\n",
    "   - κ° ν•μ΄νΌνλΌλ―Έν„° μ΅°ν•©λ§λ‹¤ ν•™μµ, κ²€μ¦ ν‰κ°€ λ£¨ν”„ κµ¬μ„±\n",
    "\n",
    "4. [ ] μ„±λ¥ κΈ°μ¤€ μ •μ\n",
    "   - μ: validation loss, accuracy, F1 score, power spectrum error λ“±\n",
    "\n",
    "5. [ ] κ²°κ³Ό κΈ°λ΅ λ° μ •λ¦¬\n",
    "   - κ° μ‹¤ν—λ§λ‹¤ config, μ„±λ¥ metric, log, μ‹κ°ν™” λ“±μ„ μλ™ μ €μ¥\n",
    "\n",
    "6. [ ] μµμ  μ΅°ν•© μ„ νƒ λ° λ¶„μ„\n",
    "   - best config μ„ νƒ + μ¤‘μ”λ„ λ¶„μ„ (e.g., via optunaβ€™s feature importance)\n",
    "\n",
    "7. [ ] μ„ νƒλ μ„¤μ •μΌλ΅ full training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589206e-f69f-4714-9d6e-76c5d571842b",
   "metadata": {},
   "source": [
    "λ”¥λ¬λ‹ λ¨λΈμ—μ„ κ³µν†µμ μΌλ΅ **νλ‹ λ€μƒμ΄ λλ” ν•μ΄νΌνλΌλ―Έν„°**λ“¤μ„ μ•„λμ™€ κ°™μ΄ λ¶„λ¥ν•΄ μ •λ¦¬ν•  μ μμµλ‹λ‹¤. μ΄ λ¦¬μ¤νΈλ” λ€λ¶€λ¶„μ λ”¥λ¬λ‹ λ¨λΈβ€”CNN, Transformer, GAN, U-Net, FNO λ“±β€”μ— **κ³µν†µμ μΌλ΅ μ μ© κ°€λ¥**ν• μ”μ†λ“¤μ…λ‹λ‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### π”§ λ”¥λ¬λ‹ λ¨λΈ κ³µν†µ ν•μ΄νΌνλΌλ―Έν„° νλ‹ λ©λ΅\n",
    "\n",
    "#### π“ **Optimization κ΄€λ ¨**\n",
    "\n",
    "* [ ] **Learning Rate** (`lr`): ν•™μµ μ†λ„. κ°€μ¥ μ¤‘μ”ν• ν•μ΄νΌνλΌλ―Έν„° μ¤‘ ν•λ‚.\n",
    "* [ ] **Optimizer Type**: `Adam`, `AdamW`, `SGD`, `RMSprop` λ“±\n",
    "* [ ] **Weight Decay**: L2 regularization κ³„μ\n",
    "* [ ] **Momentum** (SGD κ³„μ—΄): κ΄€μ„± ν¨κ³Ό μ΅°μ \n",
    "* [ ] **Gradient Clipping**: gradient exploding λ°©μ§€\n",
    "\n",
    "#### π“ **Batch λ° Epoch κ΄€λ ¨**\n",
    "\n",
    "* [ ] **Batch Size**: λ©”λ¨λ¦¬, ν•™μµ μ•μ •μ„±, μΌλ°ν™”μ— μν–¥\n",
    "* [ ] **Number of Epochs**: ν•™μµ λ°λ³µ νμ\n",
    "* [ ] **Early Stopping Patience**: κ³Όμ ν•© λ°©μ§€λ¥Ό μ„ν• μ΅°κΈ° μΆ…λ£ κΈ°μ¤€\n",
    "\n",
    "#### π“ **Learning Rate Scheduler**\n",
    "\n",
    "* [ ] **Scheduler Type**: `StepLR`, `CosineAnnealing`, `ReduceLROnPlateau`, `CyclicLR` λ“±\n",
    "* [ ] **Scheduler Parameters**: step size, gamma, warm-up steps λ“±\n",
    "\n",
    "#### π“ **Model Architecture κ΄€λ ¨**\n",
    "\n",
    "* [ ] **Model Depth**: λ μ΄μ–΄ μ (e.g., residual blocks, transformer layers)\n",
    "* [ ] **Hidden Size / Channels**: λ μ΄μ–΄λ‹Ή feature μ (e.g., `n_gf`, `dim`, `channels`)\n",
    "* [ ] **Dropout Rate**: overfitting λ°©μ§€λ¥Ό μ„ν• regularization\n",
    "* [ ] **Activation Function**: ReLU, LeakyReLU, GELU, Mish λ“±\n",
    "\n",
    "#### π“ **Loss Function κ΄€λ ¨**\n",
    "\n",
    "* [ ] **Loss Weighting**: λ‹¤μ–‘ν• μ†μ‹¤ ν•¨μ κ°„ κ°€μ¤‘μΉ (e.g., MSE + SpectralLoss)\n",
    "* [ ] **Label Smoothing**: classification κ³„μ—΄μ—μ„ μ •λ‹µ λ¶„ν¬λ¥Ό λ¶€λ“λ½κ²\n",
    "\n",
    "#### π“ **Normalization λ° Regularization**\n",
    "\n",
    "* [ ] **Normalization Type**: BatchNorm, InstanceNorm, GroupNorm λ“±\n",
    "* [ ] **Dropout Position λ° μ μ© μ—¬λ¶€**\n",
    "* [ ] **Data Augmentation κ°•λ„**: (μ£Όλ΅ μ΄λ―Έμ§€ κ³„μ—΄)\n",
    "\n",
    "#### π“ **AMP λ° Precision**\n",
    "\n",
    "* [ ] **Mixed Precision μ‚¬μ© μ—¬λ¶€**: AMP on/off (`torch.amp`)\n",
    "* [ ] **Gradient Accumulation Steps**: μ‘μ€ λ°°μΉμΌ λ• μ μ©\n",
    "\n",
    "---\n",
    "\n",
    "### π’΅ μ°Έκ³ : μ‹¤ν— μ„¤κ³„ μ‹ κ³ λ ¤μ‚¬ν•­\n",
    "\n",
    "* νλΌλ―Έν„° κ°„ μƒνΈμ‘μ©μ΄ μμΌλ―€λ΅ **ν•λ‚μ”© μμ°¨μ μΌλ΅ μ΅°μ •**ν•κ±°λ‚, Optuna λ“±μΌλ΅ **μλ™ν™”λ νƒμƒ‰**μ„ μ¶”μ².\n",
    "* νΉν `learning rate`, `batch size`, `model size`λ” **κ°•ν•κ² μ—°κ΄€λ¨** β†’ ν•¨κ» κ³ λ ¤ν•΄μ•Ό ν•¨.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b51f0-2280-4afd-a460-09cc0b1d84a8",
   "metadata": {},
   "source": [
    "Optunaλ” λ”¥λ¬λ‹ λ° λ¨Έμ‹ λ¬λ‹ λ¨λΈμ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ„ μλ™ν™”ν•΄μ£Όλ” νμ΄μ¬ κΈ°λ° μ¤ν”μ†μ¤ λΌμ΄λΈλ¬λ¦¬μ…λ‹λ‹¤. κ°„λ‹¨ν λ§ν•΄:\n",
    "\n",
    "π” β€κ°€μ¥ μΆ‹μ€ ν•μ΄νΌνλΌλ―Έν„° μ΅°ν•©μ„ μλ™μΌλ΅ μ°Ύμ•„μ£Όλ” λ‘λ‘ν• μ‹¤ν— μ¤μΌ€μ¤„λ¬β€μ…λ‹λ‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b462b-731c-451b-9070-1c40eca43f6a",
   "metadata": {},
   "source": [
    "β… Optunaλ΅ μ°Ύμ„ μ μλ” ν•μ΄νΌνλΌλ―Έν„°\n",
    "μ΄λ“¤μ€ μμΉμ μΌλ΅ ν‘ν„λκ³ , λ…ν™•ν•κ² ν‰κ°€ κ°€λ¥ν•λ©°, μ£Όμ–΄μ§„ λ²”μ„μ—μ„ λ°λ³µμ μΌλ΅ μ‹¤ν—ν•  μ μλ” νλΌλ―Έν„°λ“¤μ…λ‹λ‹¤:\n",
    "    \n",
    "λ¶„λ¥\tμμ‹\n",
    "\n",
    "ν•™μµ κ΄€λ ¨\tlearning_rate, batch_size, weight_decay, dropout_rate\n",
    "\n",
    "λ¨λΈ κµ¬μ΅°\tnum_layers, hidden_dim, kernel_size, activation (ReLU vs. Mish λ“±)\n",
    "\n",
    "Regularization\tdropout, L2 penalty, label smoothing\n",
    "\n",
    "Optimizer μΆ…λ¥ λ° νλΌλ―Έν„°\toptimizer (Adam vs. SGD), beta1, momentum\n",
    "\n",
    "Loss κµ¬μ„± λΉ„μ¨\tGANμ—μ„ Ξ»_fm, Ξ»_cc, Ξ»_l1, Spectral loss weight λ“±\n",
    "\n",
    "λ°μ΄ν„° μ¦κ°•\tμ¦κ°• μ—¬λ¶€, ν™•λ¥ , κ°•λ„ (aug_prob=0.3, noise_std=0.01 λ“±)\n",
    "\n",
    "κΈ°νƒ€\tscheduler μ ν• λ° decay step/ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a37f22-a1a6-4af4-9b0e-3e0264280fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
