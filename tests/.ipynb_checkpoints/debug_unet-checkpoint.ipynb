{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6796af5c-c7af-4d53-b7e9-eb3a7307c4f2",
   "metadata": {},
   "source": [
    "### 🔧 Cell 0: Configure Import Paths\n",
    "\n",
    "This cell appends the parent directory (`..`) to `sys.path` to ensure that shared modules such as `shared/` and `models/` can be imported seamlessly throughout the notebook. This is essential for accessing custom modules like `data_loader.py` or model definitions located outside the notebook's root directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a2823d-698b-4dbe-8a1a-f2025e0c6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: 모듈 import를 위한 경로 설정\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))  # shared, models 디렉토리 접근 가능하도록 경로 추가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120eca64-74b5-4b69-b008-145ce43bae9a",
   "metadata": {},
   "source": [
    "### 🧪 Cell 1: Check PyTorch and GPU Environment\n",
    "\n",
    "This cell verifies the current environment configuration:\n",
    "\n",
    "- Prints the installed PyTorch version.\n",
    "- Checks whether a CUDA-compatible GPU is available.\n",
    "- If available, displays the GPU's name.\n",
    "\n",
    "This ensures that the code will utilize GPU acceleration if supported by the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bbd22ef-4755-4172-b973-a413512d27c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch version: 2.6.0+cu124\n",
      "🚀 GPU available: True\n",
      "🧠 GPU name: Quadro RTX 5000\n",
      "💾 Total memory: 15.73 GiB\n",
      "📦 Reserved memory: 13.08 GiB\n",
      "📈 Allocated memory: 5.32 GiB\n",
      "🟢 Free memory in reserved: 7.75 GiB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 환경 확인\n",
    "import torch\n",
    "\n",
    "print(f\"✅ PyTorch version: {torch.__version__}\")\n",
    "print(f\"🚀 GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"🧠 GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"💾 Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"📦 Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"📈 Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"🟢 Free memory in reserved: {free_memory:.2f} GiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0103a5-de46-494e-860b-278c9572d64e",
   "metadata": {},
   "source": [
    "### 📂 Cell 2: Load Dataset\n",
    "\n",
    "This cell prepares the training dataset by:\n",
    "\n",
    "- Importing the custom `HDF5Dataset` class for loading 3D subcube data from HDF5 files.\n",
    "- Specifying the input and output directory paths containing `.h5` files.\n",
    "- Creating sorted lists of input and target file paths.\n",
    "- Initializing the dataset and wrapping it in a `DataLoader` with `batch_size=2` and shuffling enabled.\n",
    "- Displaying the shape of a sample input-output pair to confirm successful data loading.\n",
    "\n",
    "This step ensures that the model receives data in the correct format and structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3269431e-cf5f-49ff-8656-279b8e8716f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 16:05:44,481 [INFO] Logger initialized. Outputting to logs/data_loader_20250612_160544.log\n",
      "2025-06-12 16:05:44,486 [INFO] 🔍 Initializing dataset with 9 file pairs.\n",
      "2025-06-12 16:05:44,503 [INFO] 📦 Total samples across all files: 884736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample loaded: input shape = torch.Size([2, 1, 60, 60, 60]), output shape = torch.Size([2, 1, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 데이터셋 로딩\n",
    "from torch.utils.data import DataLoader\n",
    "from shared.data_loader import HDF5Dataset\n",
    "import os\n",
    "\n",
    "input_dir = \"/caefs/data/IllustrisTNG/subcube/input\"\n",
    "output_dir = \"/caefs/data/IllustrisTNG/subcube/output\"\n",
    "\n",
    "input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".h5\")])\n",
    "output_files = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".h5\")])\n",
    "\n",
    "dataset = HDF5Dataset(input_files, output_files)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "print(f\"✅ Sample loaded: input shape = {x.shape}, output shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b0847-c104-4ac9-b975-169fc61323bf",
   "metadata": {},
   "source": [
    "### 🧠 Cell 3: Initialize U-Net Model\n",
    "\n",
    "This cell initializes the 3D U-Net model for training:\n",
    "\n",
    "- Imports the custom `UNet3D` architecture from the project’s model directory.\n",
    "- Detects whether a CUDA-compatible GPU is available and sets the appropriate device.\n",
    "- Instantiates the model and moves it to the selected device.\n",
    "- Sets the model to training mode using `model.train()`.\n",
    "\n",
    "This prepares the neural network for forward and backward passes during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97562d6-cf1e-4761-8b2d-3aef1467e88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ U-Net model loaded and set to training mode.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: U-Net 초기화\n",
    "from models.unet.model import UNet3D\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet3D().to(device)\n",
    "model.train()\n",
    "print(\"✅ U-Net model loaded and set to training mode.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5efab-e694-477e-b3db-2929b429ceed",
   "metadata": {},
   "source": [
    "### 📊 Cell 4: Display U-Net Model Summary\n",
    "\n",
    "This cell uses the `torchinfo` library to generate a detailed summary of the U-Net model:\n",
    "\n",
    "- Provides the model with a dummy input tensor of shape `(2, 1, 60, 60, 60)` representing a batch of 2 subcubes.\n",
    "- Displays information for each layer, including input/output shapes, number of parameters, and kernel sizes.\n",
    "\n",
    "This summary helps verify the model architecture, parameter count, and compatibility with the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69522b1-2e56-45e4-a53f-e5c8b4aeb991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "UNet3D                                   [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "├─ConvBlockEnc: 1-1                      [2, 1, 60, 60, 60]        [2, 128, 30, 30, 30]      --                        --\n",
       "│    └─ReplicationPad3d: 2-1             [2, 1, 60, 60, 60]        [2, 1, 64, 64, 64]        --                        --\n",
       "│    └─Conv3d: 2-2                       [2, 1, 64, 64, 64]        [2, 128, 30, 30, 30]      16,128                    [5, 5, 5]\n",
       "│    └─BatchNorm3d: 2-3                  [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      256                       --\n",
       "│    └─ReLU: 2-4                         [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      --                        --\n",
       "├─ConvBlockEnc: 1-2                      [2, 128, 30, 30, 30]      [2, 256, 15, 15, 15]      --                        --\n",
       "│    └─ReplicationPad3d: 2-5             [2, 128, 30, 30, 30]      [2, 128, 34, 34, 34]      --                        --\n",
       "│    └─Conv3d: 2-6                       [2, 128, 34, 34, 34]      [2, 256, 15, 15, 15]      4,096,256                 [5, 5, 5]\n",
       "│    └─BatchNorm3d: 2-7                  [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      512                       --\n",
       "│    └─ReLU: 2-8                         [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      --                        --\n",
       "├─ConvBlockEnc: 1-3                      [2, 256, 15, 15, 15]      [2, 512, 8, 8, 8]         --                        --\n",
       "│    └─ReplicationPad3d: 2-9             [2, 256, 15, 15, 15]      [2, 256, 19, 19, 19]      --                        --\n",
       "│    └─Conv3d: 2-10                      [2, 256, 19, 19, 19]      [2, 512, 8, 8, 8]         16,384,512                [5, 5, 5]\n",
       "│    └─BatchNorm3d: 2-11                 [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         1,024                     --\n",
       "│    └─ReLU: 2-12                        [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         --                        --\n",
       "├─ConvBlockEnc: 1-4                      [2, 512, 8, 8, 8]         [2, 1024, 4, 4, 4]        --                        --\n",
       "│    └─ReplicationPad3d: 2-13            [2, 512, 8, 8, 8]         [2, 512, 12, 12, 12]      --                        --\n",
       "│    └─Conv3d: 2-14                      [2, 512, 12, 12, 12]      [2, 1024, 4, 4, 4]        65,537,024                [5, 5, 5]\n",
       "│    └─BatchNorm3d: 2-15                 [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        2,048                     --\n",
       "│    └─ReLU: 2-16                        [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        --                        --\n",
       "├─ConvBlockEnc: 1-5                      [2, 1024, 4, 4, 4]        [2, 2048, 2, 2, 2]        --                        --\n",
       "│    └─ReplicationPad3d: 2-17            [2, 1024, 4, 4, 4]        [2, 1024, 8, 8, 8]        --                        --\n",
       "│    └─Conv3d: 2-18                      [2, 1024, 8, 8, 8]        [2, 2048, 2, 2, 2]        262,146,048               [5, 5, 5]\n",
       "│    └─BatchNorm3d: 2-19                 [2, 2048, 2, 2, 2]        [2, 2048, 2, 2, 2]        4,096                     --\n",
       "│    └─ReLU: 2-20                        [2, 2048, 2, 2, 2]        [2, 2048, 2, 2, 2]        --                        --\n",
       "├─ConvBlockDec: 1-6                      [2, 2048, 2, 2, 2]        [2, 1024, 4, 4, 4]        --                        --\n",
       "│    └─Upsample: 2-21                    [2, 2048, 2, 2, 2]        [2, 2048, 4, 4, 4]        --                        --\n",
       "│    └─ReplicationPad3d: 2-22            [2, 3072, 4, 4, 4]        [2, 3072, 6, 6, 6]        --                        --\n",
       "│    └─Conv3d: 2-23                      [2, 3072, 6, 6, 6]        [2, 1024, 4, 4, 4]        84,935,680                [3, 3, 3]\n",
       "│    └─BatchNorm3d: 2-24                 [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        2,048                     --\n",
       "│    └─ReLU: 2-25                        [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        --                        --\n",
       "├─ConvBlockDec: 1-7                      [2, 1024, 4, 4, 4]        [2, 512, 8, 8, 8]         --                        --\n",
       "│    └─Upsample: 2-26                    [2, 1024, 4, 4, 4]        [2, 1024, 8, 8, 8]        --                        --\n",
       "│    └─ReplicationPad3d: 2-27            [2, 1536, 8, 8, 8]        [2, 1536, 10, 10, 10]     --                        --\n",
       "│    └─Conv3d: 2-28                      [2, 1536, 10, 10, 10]     [2, 512, 8, 8, 8]         21,234,176                [3, 3, 3]\n",
       "│    └─BatchNorm3d: 2-29                 [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         1,024                     --\n",
       "│    └─ReLU: 2-30                        [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         --                        --\n",
       "├─ConvBlockDec: 1-8                      [2, 512, 8, 8, 8]         [2, 256, 15, 15, 15]      --                        --\n",
       "│    └─Upsample: 2-31                    [2, 512, 8, 8, 8]         [2, 512, 16, 16, 16]      --                        --\n",
       "│    └─ReplicationPad3d: 2-32            [2, 768, 15, 15, 15]      [2, 768, 17, 17, 17]      --                        --\n",
       "│    └─Conv3d: 2-33                      [2, 768, 17, 17, 17]      [2, 256, 15, 15, 15]      5,308,672                 [3, 3, 3]\n",
       "│    └─BatchNorm3d: 2-34                 [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      512                       --\n",
       "│    └─ReLU: 2-35                        [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      --                        --\n",
       "├─ConvBlockDec: 1-9                      [2, 256, 15, 15, 15]      [2, 128, 30, 30, 30]      --                        --\n",
       "│    └─Upsample: 2-36                    [2, 256, 15, 15, 15]      [2, 256, 30, 30, 30]      --                        --\n",
       "│    └─ReplicationPad3d: 2-37            [2, 384, 30, 30, 30]      [2, 384, 32, 32, 32]      --                        --\n",
       "│    └─Conv3d: 2-38                      [2, 384, 32, 32, 32]      [2, 128, 30, 30, 30]      1,327,232                 [3, 3, 3]\n",
       "│    └─BatchNorm3d: 2-39                 [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      256                       --\n",
       "│    └─ReLU: 2-40                        [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      --                        --\n",
       "├─ConvBlockDec: 1-10                     [2, 128, 30, 30, 30]      [2, 1, 60, 60, 60]        --                        --\n",
       "│    └─Upsample: 2-41                    [2, 128, 30, 30, 30]      [2, 128, 60, 60, 60]      --                        --\n",
       "│    └─ReplicationPad3d: 2-42            [2, 129, 60, 60, 60]      [2, 129, 62, 62, 62]      --                        --\n",
       "│    └─Conv3d: 2-43                      [2, 129, 62, 62, 62]      [2, 1, 60, 60, 60]        3,484                     [3, 3, 3]\n",
       "│    └─BatchNorm3d: 2-44                 [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        2                         --\n",
       "│    └─ReLU: 2-45                        [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "├─Tanh: 1-11                             [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 461,000,990\n",
       "Trainable params: 461,000,990\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 199.51\n",
       "============================================================================================================================================\n",
       "Input size (MB): 1.73\n",
       "Forward/backward pass size (MB): 304.89\n",
       "Params size (MB): 1844.00\n",
       "Estimated Total Size (MB): 2150.62\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(2, 1, 60, 60, 60), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a142f-560d-4b23-97fb-34bd863a686b",
   "metadata": {},
   "source": [
    "### ⚙️ Cell 5: Batch Size Compatibility Test\n",
    "\n",
    "This cell defines and runs a function to test whether various batch sizes can be processed without running into memory or dimensional errors:\n",
    "\n",
    "- Defines `test_batch_size(batch_size)` to:\n",
    "  - Create a `DataLoader` with the specified batch size.\n",
    "  - Instantiate and move the `UNet3D` model to the GPU.\n",
    "  - Attempt a single forward pass with one batch.\n",
    "- Catches and prints runtime errors (e.g., CUDA OOM or dimension mismatch).\n",
    "- Iterates over a list of candidate batch sizes: `[32, 16, 8, 4, 2, 1]`.\n",
    "\n",
    "This test helps determine the largest feasible batch size that can be used on the current GPU without errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c934992-e02f-4620-a7a3-01b09d72b7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed with batch_size=32: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacity of 15.73 GiB of which 808.50 MiB is free. Process 12502 has 26.06 MiB memory in use. Including non-PyTorch memory, this process has 14.91 GiB memory in use. Of the allocated memory 13.89 GiB is allocated by PyTorch, and 911.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "✅ Success with batch_size=16\n",
      "✅ Success with batch_size=8\n",
      "✅ Success with batch_size=4\n",
      "✅ Success with batch_size=2\n",
      "✅ Success with batch_size=1\n"
     ]
    }
   ],
   "source": [
    "def test_batch_size(batch_size):\n",
    "    try:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        model = UNet3D().cuda()  # 사용 중인 모델로 교체\n",
    "        for x, y in loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            pred = model(x)\n",
    "            print(f\"✅ Success with batch_size={batch_size}\")\n",
    "            break  # 한 번만 테스트\n",
    "    except RuntimeError as e:\n",
    "        print(f\"❌ Failed with batch_size={batch_size}: {str(e).splitlines()[0]}\")\n",
    "\n",
    "# 테스트할 batch size 리스트\n",
    "for bs in [32, 16, 8, 4, 2, 1]:\n",
    "    test_batch_size(bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88202d77-80b2-410e-b47a-a0872e002f57",
   "metadata": {},
   "source": [
    "### 🔍 Cell 4: Test Loss Functions\n",
    "\n",
    "This cell verifies the implementation of loss functions used during training:\n",
    "\n",
    "- Imports `mse_loss` and `spectral_loss` from the project's `shared.losses` module.\n",
    "- Computes the Mean Squared Error (MSE) loss between a batch of input and target tensors.\n",
    "- Prints the resulting loss value for confirmation.\n",
    "\n",
    "This test ensures that the loss function operates correctly and is compatible with the loaded data format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07095954-8407-4db7-abd5-a3eba27a2033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MSE Loss on batch: 76.8758\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 손실 함수 테스트\n",
    "from shared.losses import mse_loss, spectral_loss\n",
    "\n",
    "loss_val = mse_loss(x.to(device), y.to(device))\n",
    "print(f\"✅ MSE Loss on batch: {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad65e1-ad9a-41e9-8892-d4362148f81b",
   "metadata": {},
   "source": [
    "### 🧮 Cell 5: Set Optimizer and Learning Rate Scheduler\n",
    "\n",
    "This cell initializes the optimization strategy for training:\n",
    "\n",
    "- Uses the Adam optimizer with a learning rate of `1e-4` to update model parameters.\n",
    "- Applies a cosine annealing learning rate scheduler (`CosineAnnealingLR`) with `T_max=10`, which gradually reduces the learning rate following a cosine curve over epochs.\n",
    "\n",
    "These components help improve convergence and training stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d172b3-07cb-4eeb-b7f6-22c2cece4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimizer and LR scheduler initialized.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Optimizer 및 스케줄러 설정\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(\"✅ Optimizer and LR scheduler initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f41253-1fcc-431b-b015-b39b8fd0128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 10/442368 [00:06<76:13:58,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 1 (partial) Loss: 0.4469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 10/442368 [00:06<76:51:14,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 2 (partial) Loss: 0.4386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 10/442368 [00:06<77:02:29,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 3 (partial) Loss: 0.4386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: 빠른 학습 루프 (1 epoch, 일부 batch만)\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "n_batch = 10  # 테스트용으로 10개 배치만 학습\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        if i >= n_batch:\n",
    "            break\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = mse_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"📉 Epoch {epoch+1} (partial) Loss: {total_loss / n_batch:.4f}\")\n",
    "    print(f\"📉 Epoch {epoch+1} (partial) Loss: {total_loss / n_batch:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d77be-3bd8-42e9-a65f-9681f4befd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: 모델 저장\n",
    "save_path = \"unet3d_test_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"✅ Model saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
