{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c59398f-db66-4173-a4b1-a3075fa96d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check_gpu_diagnostic.py\n",
    "\n",
    "Description:\n",
    "    Checks for GPU availability using PyTorch and prints out device information.\n",
    "    Also performs extended diagnostics to help troubleshoot why GPU is not detected.\n",
    "\n",
    "Author: Mingyeong Yang\n",
    "Email: mmingyeong@kasi.re.kr\n",
    "Created: 2025-06-10\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c62fd7d-d5eb-4beb-9e13-31c7569416e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 15:31:19,137 [INFO] üöÄ Starting extended GPU availability check...\n",
      "2025-06-11 15:31:19,140 [INFO] Torch version: 2.6.0+cu124\n",
      "2025-06-11 15:31:19,142 [INFO] Python version: 3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 17:29:18) [GCC 11.2.0]\n",
      "2025-06-11 15:31:19,142 [INFO] Platform: linux\n"
     ]
    }
   ],
   "source": [
    "# üîß Set up logger\n",
    "log_dir = \"logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_path = os.path.join(log_dir, f\"check_gpu_diagnostic_{timestamp}.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_path),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"üöÄ Starting extended GPU availability check...\")\n",
    "\n",
    "logger.info(f\"Torch version: {torch.__version__}\")\n",
    "logger.info(f\"Python version: {sys.version}\")\n",
    "logger.info(f\"Platform: {sys.platform}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9564f4f-287f-46ca-9aba-04cee2c925bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 15:31:19,176 [INFO] üîç Checking nvidia-smi...\n",
      "2025-06-11 15:31:19,274 [INFO] nvidia-smi output:\n",
      "Wed Jun 11 15:31:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 5000                On  |   00000000:AF:00.0 Off |                  Off |\n",
      "| 33%   27C    P8             13W /  230W |      30MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     12502      C   nvidia-cuda-mps-server                         26MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "2025-06-11 15:31:19,276 [INFO] CUDA_HOME/CUDA_PATH: /usr/local/cuda-11.8\n",
      "2025-06-11 15:31:19,278 [INFO] PATH: /opt/anaconda3/2023.03/bin:/usr/local/cuda-11.8/bin:/usr/local/bin:/usr/local/sm/bin:/opt/anaconda3/2023.03/condabin:/usr/opt/intel/oneapi/advisor/2022.0.0/bin64:/usr/opt/intel/oneapi/vtune/2022.0.0/bin64:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/bin/intel64:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/bin:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/lib/oclfpga/bin:/usr/opt/intel/oneapi/debugger/2021.5.0/gdb/intel64/bin:/usr/local/cuda-11.0/bin:/usr/local/cuda-11.0/samples/bin/x86_64/linux/release:/usr/local/NaMaster/bin:/opt/gsl/2.6/bin:/usr/local/openmpi-2.1.1-intel2017/bin:/usr/local/mpich/bin:/usr/local/mpich2/bin:/usr/local/pbs/sbin:/usr/local/pbs/bin:/usr/local/maui/sbin:/usr/local/maui/bin:/usr/local/bwatch:/usr/local/hpc/bin:/opt/absoft/bin:/usr/local/ldap/bin:/usr/local/ldap/sbin:/usr/lib64/qt-3.3/bin:/home/users/mmingyeong/perl5/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/local/ganglia/bin:/home/users/mmingyeong/.local/bin:/home/users/mmingyeong/bin\n",
      "2025-06-11 15:31:19,278 [INFO] LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/opt/intel/oneapi/mkl/2022.0.2/lib/intel64:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/lib/oclfpga/host/linux64/lib:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/lib:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/lib/x64:/usr/opt/intel/oneapi/compiler/2022.0.2/linux/compiler/lib/intel64_lin:/usr/opt/intel/oneapi/tbb/2021.5.1/lib/intel64/gcc4.8:/usr/opt/intel/oneapi/debugger/2021.5.0/gdb/intel64/lib:/usr/opt/intel/oneapi/debugger/2021.5.0/libipt/intel64/lib:/usr/opt/intel/oneapi/debugger/2021.5.0/dep/lib:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/lib:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/NaMaster/lib:/usr/local/gsl/2.5/lib:/opt/gsl/2.6/lib:/usr/local/openmpi-2.1.1-intel2017/lib:/opt/intel/mkl/8.1.1/lib/em64t:\n"
     ]
    }
   ],
   "source": [
    "# 1. Check nvidia-smi\n",
    "logger.info(\"üîç Checking nvidia-smi...\")\n",
    "try:\n",
    "    result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        logger.info(\"nvidia-smi output:\\n\" + result.stdout)\n",
    "    else:\n",
    "        logger.warning(\"nvidia-smi failed:\\n\" + result.stderr)\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"nvidia-smi not found. NVIDIA driver may not be installed or PATH is not set.\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"nvidia-smi check error: {e}\")\n",
    "\n",
    "# 2. Check CUDA_HOME and environment variables\n",
    "cuda_home = os.environ.get(\"CUDA_HOME\") or os.environ.get(\"CUDA_PATH\")\n",
    "logger.info(f\"CUDA_HOME/CUDA_PATH: {cuda_home}\")\n",
    "logger.info(f\"PATH: {os.environ.get('PATH')}\")\n",
    "logger.info(f\"LD_LIBRARY_PATH: {os.environ.get('LD_LIBRARY_PATH')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7513e712-d8d0-4028-944d-a3acda16d01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 15:31:19,288 [INFO] üîç Checking torch.cuda properties...\n",
      "2025-06-11 15:31:19,306 [INFO] torch.cuda.is_available(): True\n",
      "2025-06-11 15:31:19,307 [INFO] torch.version.cuda: 12.4\n",
      "2025-06-11 15:31:19,312 [INFO] torch.backends.cudnn.version(): 90100\n",
      "2025-06-11 15:31:19,329 [INFO] torch.cuda.device_count(): 1\n",
      "2025-06-11 15:31:19,334 [INFO] torch.cuda.current_device(): 0\n",
      "2025-06-11 15:31:19,335 [INFO] torch.cuda.get_device_name(0): Quadro RTX 5000\n",
      "2025-06-11 15:31:19,337 [INFO] torch._C module found.\n"
     ]
    }
   ],
   "source": [
    "# 3. Check torch.cuda properties\n",
    "logger.info(\"üîç Checking torch.cuda properties...\")\n",
    "try:\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    logger.info(f\"torch.cuda.is_available(): {gpu_available}\")\n",
    "    logger.info(f\"torch.version.cuda: {torch.version.cuda}\")\n",
    "    logger.info(f\"torch.backends.cudnn.version(): {torch.backends.cudnn.version()}\")\n",
    "    logger.info(f\"torch.cuda.device_count(): {torch.cuda.device_count()}\")\n",
    "    logger.info(f\"torch.cuda.current_device(): {torch.cuda.current_device() if gpu_available else 'N/A'}\")\n",
    "    logger.info(f\"torch.cuda.get_device_name(0): {torch.cuda.get_device_name(0) if gpu_available else 'N/A'}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error querying torch.cuda: {e}\")\n",
    "\n",
    "# 4. Try importing torch with CUDA extension explicitly\n",
    "try:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.find_spec(\"torch._C\")\n",
    "    if spec is not None:\n",
    "        logger.info(\"torch._C module found.\")\n",
    "    else:\n",
    "        logger.warning(\"torch._C module NOT found.\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"torch._C import check error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd06d98-ef57-4df2-8c6f-9e9250991739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 15:31:19,367 [INFO] ‚úÖ GPU detected by PyTorch.\n",
      "2025-06-11 15:31:19,368 [INFO] ‚úÖ Extended GPU check complete.\n",
      "2025-06-11 15:31:19,369 [INFO] üîç Log saved to: logs/check_gpu_diagnostic_20250611_153119.log\n"
     ]
    }
   ],
   "source": [
    "# 5. Print summary\n",
    "if not torch.cuda.is_available():\n",
    "    logger.warning(\"‚ö† No GPU detected by PyTorch.\")\n",
    "    logger.warning(\"Possible reasons:\")\n",
    "    logger.warning(\"- NVIDIA driver not installed or not loaded\")\n",
    "    logger.warning(\"- CUDA toolkit not installed or not in PATH/LD_LIBRARY_PATH\")\n",
    "    logger.warning(\"- PyTorch not installed with CUDA support\")\n",
    "    logger.warning(\"- Running in a virtual environment without CUDA bindings\")\n",
    "    logger.warning(\"- Hardware issue or no NVIDIA GPU present\")\n",
    "else:\n",
    "    logger.info(\"‚úÖ GPU detected by PyTorch.\")\n",
    "\n",
    "logger.info(\"‚úÖ Extended GPU check complete.\")\n",
    "logger.info(f\"üîç Log saved to: {log_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
