{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6796af5c-c7af-4d53-b7e9-eb3a7307c4f2",
   "metadata": {},
   "source": [
    "### ğŸ”§ Cell 0: Configure Import Paths\n",
    "\n",
    "This cell appends the parent directory (`..`) to `sys.path` to ensure that shared modules such as `shared/` and `models/` can be imported seamlessly throughout the notebook. This is essential for accessing custom modules like `data_loader.py` or model definitions located outside the notebook's root directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a2823d-698b-4dbe-8a1a-f2025e0c6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))  # shared, models ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ê²½ë¡œ ì¶”ê°€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120eca64-74b5-4b69-b008-145ce43bae9a",
   "metadata": {},
   "source": [
    "### ğŸ§ª Cell 1: Check PyTorch and GPU Environment\n",
    "\n",
    "This cell verifies the current environment configuration:\n",
    "\n",
    "- Prints the installed PyTorch version.\n",
    "- Checks whether a CUDA-compatible GPU is available.\n",
    "- If available, displays the GPU's name.\n",
    "\n",
    "This ensures that the code will utilize GPU acceleration if supported by the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bbd22ef-4755-4172-b973-a413512d27c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch version: 2.6.0+cu124\n",
      "ğŸš€ GPU available: True\n",
      "ğŸ§  GPU name: Quadro RTX 5000\n",
      "ğŸ’¾ Total memory: 15.73 GiB\n",
      "ğŸ“¦ Reserved memory: 13.08 GiB\n",
      "ğŸ“ˆ Allocated memory: 5.32 GiB\n",
      "ğŸŸ¢ Free memory in reserved: 7.75 GiB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: í™˜ê²½ í™•ì¸\n",
    "import torch\n",
    "\n",
    "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸš€ GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"ğŸ§  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"ğŸ’¾ Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“¦ Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“ˆ Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"ğŸŸ¢ Free memory in reserved: {free_memory:.2f} GiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0103a5-de46-494e-860b-278c9572d64e",
   "metadata": {},
   "source": [
    "### ğŸ“‚ Cell 2: Load Dataset\n",
    "\n",
    "This cell prepares the training dataset by:\n",
    "\n",
    "- Importing the custom `HDF5Dataset` class for loading 3D subcube data from HDF5 files.\n",
    "- Specifying the input and output directory paths containing `.h5` files.\n",
    "- Creating sorted lists of input and target file paths.\n",
    "- Initializing the dataset and wrapping it in a `DataLoader` with `batch_size=2` and shuffling enabled.\n",
    "- Displaying the shape of a sample input-output pair to confirm successful data loading.\n",
    "\n",
    "This step ensures that the model receives data in the correct format and structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3269431e-cf5f-49ff-8656-279b8e8716f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 16:05:44,481 [INFO] Logger initialized. Outputting to logs/data_loader_20250612_160544.log\n",
      "2025-06-12 16:05:44,486 [INFO] ğŸ” Initializing dataset with 9 file pairs.\n",
      "2025-06-12 16:05:44,503 [INFO] ğŸ“¦ Total samples across all files: 884736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample loaded: input shape = torch.Size([2, 1, 60, 60, 60]), output shape = torch.Size([2, 1, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ë°ì´í„°ì…‹ ë¡œë”©\n",
    "from torch.utils.data import DataLoader\n",
    "from shared.data_loader import HDF5Dataset\n",
    "import os\n",
    "\n",
    "input_dir = \"/caefs/data/IllustrisTNG/subcube/input\"\n",
    "output_dir = \"/caefs/data/IllustrisTNG/subcube/output\"\n",
    "\n",
    "input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".h5\")])\n",
    "output_files = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".h5\")])\n",
    "\n",
    "dataset = HDF5Dataset(input_files, output_files)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "print(f\"âœ… Sample loaded: input shape = {x.shape}, output shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b0847-c104-4ac9-b975-169fc61323bf",
   "metadata": {},
   "source": [
    "### ğŸ§  Cell 3: Initialize U-Net Model\n",
    "\n",
    "This cell initializes the 3D U-Net model for training:\n",
    "\n",
    "- Imports the custom `UNet3D` architecture from the projectâ€™s model directory.\n",
    "- Detects whether a CUDA-compatible GPU is available and sets the appropriate device.\n",
    "- Instantiates the model and moves it to the selected device.\n",
    "- Sets the model to training mode using `model.train()`.\n",
    "\n",
    "This prepares the neural network for forward and backward passes during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97562d6-cf1e-4761-8b2d-3aef1467e88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… U-Net model loaded and set to training mode.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: U-Net ì´ˆê¸°í™”\n",
    "from models.unet.model import UNet3D\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet3D().to(device)\n",
    "model.train()\n",
    "print(\"âœ… U-Net model loaded and set to training mode.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5efab-e694-477e-b3db-2929b429ceed",
   "metadata": {},
   "source": [
    "### ğŸ“Š Cell 4: Display U-Net Model Summary\n",
    "\n",
    "This cell uses the `torchinfo` library to generate a detailed summary of the U-Net model:\n",
    "\n",
    "- Provides the model with a dummy input tensor of shape `(2, 1, 60, 60, 60)` representing a batch of 2 subcubes.\n",
    "- Displays information for each layer, including input/output shapes, number of parameters, and kernel sizes.\n",
    "\n",
    "This summary helps verify the model architecture, parameter count, and compatibility with the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69522b1-2e56-45e4-a53f-e5c8b4aeb991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "UNet3D                                   [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "â”œâ”€ConvBlockEnc: 1-1                      [2, 1, 60, 60, 60]        [2, 128, 30, 30, 30]      --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-1             [2, 1, 60, 60, 60]        [2, 1, 64, 64, 64]        --                        --\n",
       "â”‚    â””â”€Conv3d: 2-2                       [2, 1, 64, 64, 64]        [2, 128, 30, 30, 30]      16,128                    [5, 5, 5]\n",
       "â”‚    â””â”€BatchNorm3d: 2-3                  [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      256                       --\n",
       "â”‚    â””â”€ReLU: 2-4                         [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      --                        --\n",
       "â”œâ”€ConvBlockEnc: 1-2                      [2, 128, 30, 30, 30]      [2, 256, 15, 15, 15]      --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-5             [2, 128, 30, 30, 30]      [2, 128, 34, 34, 34]      --                        --\n",
       "â”‚    â””â”€Conv3d: 2-6                       [2, 128, 34, 34, 34]      [2, 256, 15, 15, 15]      4,096,256                 [5, 5, 5]\n",
       "â”‚    â””â”€BatchNorm3d: 2-7                  [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      512                       --\n",
       "â”‚    â””â”€ReLU: 2-8                         [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      --                        --\n",
       "â”œâ”€ConvBlockEnc: 1-3                      [2, 256, 15, 15, 15]      [2, 512, 8, 8, 8]         --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-9             [2, 256, 15, 15, 15]      [2, 256, 19, 19, 19]      --                        --\n",
       "â”‚    â””â”€Conv3d: 2-10                      [2, 256, 19, 19, 19]      [2, 512, 8, 8, 8]         16,384,512                [5, 5, 5]\n",
       "â”‚    â””â”€BatchNorm3d: 2-11                 [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         1,024                     --\n",
       "â”‚    â””â”€ReLU: 2-12                        [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         --                        --\n",
       "â”œâ”€ConvBlockEnc: 1-4                      [2, 512, 8, 8, 8]         [2, 1024, 4, 4, 4]        --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-13            [2, 512, 8, 8, 8]         [2, 512, 12, 12, 12]      --                        --\n",
       "â”‚    â””â”€Conv3d: 2-14                      [2, 512, 12, 12, 12]      [2, 1024, 4, 4, 4]        65,537,024                [5, 5, 5]\n",
       "â”‚    â””â”€BatchNorm3d: 2-15                 [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        2,048                     --\n",
       "â”‚    â””â”€ReLU: 2-16                        [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        --                        --\n",
       "â”œâ”€ConvBlockEnc: 1-5                      [2, 1024, 4, 4, 4]        [2, 2048, 2, 2, 2]        --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-17            [2, 1024, 4, 4, 4]        [2, 1024, 8, 8, 8]        --                        --\n",
       "â”‚    â””â”€Conv3d: 2-18                      [2, 1024, 8, 8, 8]        [2, 2048, 2, 2, 2]        262,146,048               [5, 5, 5]\n",
       "â”‚    â””â”€BatchNorm3d: 2-19                 [2, 2048, 2, 2, 2]        [2, 2048, 2, 2, 2]        4,096                     --\n",
       "â”‚    â””â”€ReLU: 2-20                        [2, 2048, 2, 2, 2]        [2, 2048, 2, 2, 2]        --                        --\n",
       "â”œâ”€ConvBlockDec: 1-6                      [2, 2048, 2, 2, 2]        [2, 1024, 4, 4, 4]        --                        --\n",
       "â”‚    â””â”€Upsample: 2-21                    [2, 2048, 2, 2, 2]        [2, 2048, 4, 4, 4]        --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-22            [2, 3072, 4, 4, 4]        [2, 3072, 6, 6, 6]        --                        --\n",
       "â”‚    â””â”€Conv3d: 2-23                      [2, 3072, 6, 6, 6]        [2, 1024, 4, 4, 4]        84,935,680                [3, 3, 3]\n",
       "â”‚    â””â”€BatchNorm3d: 2-24                 [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        2,048                     --\n",
       "â”‚    â””â”€ReLU: 2-25                        [2, 1024, 4, 4, 4]        [2, 1024, 4, 4, 4]        --                        --\n",
       "â”œâ”€ConvBlockDec: 1-7                      [2, 1024, 4, 4, 4]        [2, 512, 8, 8, 8]         --                        --\n",
       "â”‚    â””â”€Upsample: 2-26                    [2, 1024, 4, 4, 4]        [2, 1024, 8, 8, 8]        --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-27            [2, 1536, 8, 8, 8]        [2, 1536, 10, 10, 10]     --                        --\n",
       "â”‚    â””â”€Conv3d: 2-28                      [2, 1536, 10, 10, 10]     [2, 512, 8, 8, 8]         21,234,176                [3, 3, 3]\n",
       "â”‚    â””â”€BatchNorm3d: 2-29                 [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         1,024                     --\n",
       "â”‚    â””â”€ReLU: 2-30                        [2, 512, 8, 8, 8]         [2, 512, 8, 8, 8]         --                        --\n",
       "â”œâ”€ConvBlockDec: 1-8                      [2, 512, 8, 8, 8]         [2, 256, 15, 15, 15]      --                        --\n",
       "â”‚    â””â”€Upsample: 2-31                    [2, 512, 8, 8, 8]         [2, 512, 16, 16, 16]      --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-32            [2, 768, 15, 15, 15]      [2, 768, 17, 17, 17]      --                        --\n",
       "â”‚    â””â”€Conv3d: 2-33                      [2, 768, 17, 17, 17]      [2, 256, 15, 15, 15]      5,308,672                 [3, 3, 3]\n",
       "â”‚    â””â”€BatchNorm3d: 2-34                 [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      512                       --\n",
       "â”‚    â””â”€ReLU: 2-35                        [2, 256, 15, 15, 15]      [2, 256, 15, 15, 15]      --                        --\n",
       "â”œâ”€ConvBlockDec: 1-9                      [2, 256, 15, 15, 15]      [2, 128, 30, 30, 30]      --                        --\n",
       "â”‚    â””â”€Upsample: 2-36                    [2, 256, 15, 15, 15]      [2, 256, 30, 30, 30]      --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-37            [2, 384, 30, 30, 30]      [2, 384, 32, 32, 32]      --                        --\n",
       "â”‚    â””â”€Conv3d: 2-38                      [2, 384, 32, 32, 32]      [2, 128, 30, 30, 30]      1,327,232                 [3, 3, 3]\n",
       "â”‚    â””â”€BatchNorm3d: 2-39                 [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      256                       --\n",
       "â”‚    â””â”€ReLU: 2-40                        [2, 128, 30, 30, 30]      [2, 128, 30, 30, 30]      --                        --\n",
       "â”œâ”€ConvBlockDec: 1-10                     [2, 128, 30, 30, 30]      [2, 1, 60, 60, 60]        --                        --\n",
       "â”‚    â””â”€Upsample: 2-41                    [2, 128, 30, 30, 30]      [2, 128, 60, 60, 60]      --                        --\n",
       "â”‚    â””â”€ReplicationPad3d: 2-42            [2, 129, 60, 60, 60]      [2, 129, 62, 62, 62]      --                        --\n",
       "â”‚    â””â”€Conv3d: 2-43                      [2, 129, 62, 62, 62]      [2, 1, 60, 60, 60]        3,484                     [3, 3, 3]\n",
       "â”‚    â””â”€BatchNorm3d: 2-44                 [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        2                         --\n",
       "â”‚    â””â”€ReLU: 2-45                        [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "â”œâ”€Tanh: 1-11                             [2, 1, 60, 60, 60]        [2, 1, 60, 60, 60]        --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 461,000,990\n",
       "Trainable params: 461,000,990\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 199.51\n",
       "============================================================================================================================================\n",
       "Input size (MB): 1.73\n",
       "Forward/backward pass size (MB): 304.89\n",
       "Params size (MB): 1844.00\n",
       "Estimated Total Size (MB): 2150.62\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(2, 1, 60, 60, 60), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a142f-560d-4b23-97fb-34bd863a686b",
   "metadata": {},
   "source": [
    "### âš™ï¸ Cell 5: Batch Size Compatibility Test\n",
    "\n",
    "This cell defines and runs a function to test whether various batch sizes can be processed without running into memory or dimensional errors:\n",
    "\n",
    "- Defines `test_batch_size(batch_size)` to:\n",
    "  - Create a `DataLoader` with the specified batch size.\n",
    "  - Instantiate and move the `UNet3D` model to the GPU.\n",
    "  - Attempt a single forward pass with one batch.\n",
    "- Catches and prints runtime errors (e.g., CUDA OOM or dimension mismatch).\n",
    "- Iterates over a list of candidate batch sizes: `[32, 16, 8, 4, 2, 1]`.\n",
    "\n",
    "This test helps determine the largest feasible batch size that can be used on the current GPU without errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c934992-e02f-4620-a7a3-01b09d72b7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed with batch_size=32: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacity of 15.73 GiB of which 808.50 MiB is free. Process 12502 has 26.06 MiB memory in use. Including non-PyTorch memory, this process has 14.91 GiB memory in use. Of the allocated memory 13.89 GiB is allocated by PyTorch, and 911.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "âœ… Success with batch_size=16\n",
      "âœ… Success with batch_size=8\n",
      "âœ… Success with batch_size=4\n",
      "âœ… Success with batch_size=2\n",
      "âœ… Success with batch_size=1\n"
     ]
    }
   ],
   "source": [
    "def test_batch_size(batch_size):\n",
    "    try:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        model = UNet3D().cuda()  # ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ë¡œ êµì²´\n",
    "        for x, y in loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            pred = model(x)\n",
    "            print(f\"âœ… Success with batch_size={batch_size}\")\n",
    "            break  # í•œ ë²ˆë§Œ í…ŒìŠ¤íŠ¸\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âŒ Failed with batch_size={batch_size}: {str(e).splitlines()[0]}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  batch size ë¦¬ìŠ¤íŠ¸\n",
    "for bs in [32, 16, 8, 4, 2, 1]:\n",
    "    test_batch_size(bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88202d77-80b2-410e-b47a-a0872e002f57",
   "metadata": {},
   "source": [
    "### ğŸ” Cell 4: Test Loss Functions\n",
    "\n",
    "This cell verifies the implementation of loss functions used during training:\n",
    "\n",
    "- Imports `mse_loss` and `spectral_loss` from the project's `shared.losses` module.\n",
    "- Computes the Mean Squared Error (MSE) loss between a batch of input and target tensors.\n",
    "- Prints the resulting loss value for confirmation.\n",
    "\n",
    "This test ensures that the loss function operates correctly and is compatible with the loaded data format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07095954-8407-4db7-abd5-a3eba27a2033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MSE Loss on batch: 76.8758\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
    "from shared.losses import mse_loss, spectral_loss\n",
    "\n",
    "loss_val = mse_loss(x.to(device), y.to(device))\n",
    "print(f\"âœ… MSE Loss on batch: {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad65e1-ad9a-41e9-8892-d4362148f81b",
   "metadata": {},
   "source": [
    "### ğŸ§® Cell 5: Set Optimizer and Learning Rate Scheduler\n",
    "\n",
    "This cell initializes the optimization strategy for training:\n",
    "\n",
    "- Uses the Adam optimizer with a learning rate of `1e-4` to update model parameters.\n",
    "- Applies a cosine annealing learning rate scheduler (`CosineAnnealingLR`) with `T_max=10`, which gradually reduces the learning rate following a cosine curve over epochs.\n",
    "\n",
    "These components help improve convergence and training stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d172b3-07cb-4eeb-b7f6-22c2cece4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Optimizer and LR scheduler initialized.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Optimizer ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(\"âœ… Optimizer and LR scheduler initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f41253-1fcc-431b-b015-b39b8fd0128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 10/442368 [00:06<78:18:07,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Epoch 1 (partial) Loss: 0.4378\n",
      "ğŸ“‰ Epoch 1 (partial) Loss: 0.4378 | LR: 3.45e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 10/442368 [00:06<76:56:18,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Epoch 2 (partial) Loss: 0.4380\n",
      "ğŸ“‰ Epoch 2 (partial) Loss: 0.4380 | LR: 2.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 10/442368 [00:05<73:30:52,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Epoch 3 (partial) Loss: 0.4358\n",
      "ğŸ“‰ Epoch 3 (partial) Loss: 0.4358 | LR: 9.55e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: ë¹ ë¥¸ í•™ìŠµ ë£¨í”„ (1 epoch, ì¼ë¶€ batchë§Œ)\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "n_batch = 10  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 10ê°œ ë°°ì¹˜ë§Œ í•™ìŠµ\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        if i >= n_batch:\n",
    "            break\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = mse_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"ğŸ“‰ Epoch {epoch+1} (partial) Loss: {total_loss / n_batch:.4f}\")\n",
    "    print(f\"ğŸ“‰ Epoch {epoch+1} (partial) Loss: {total_loss / n_batch:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9d77be-3bd8-42e9-a65f-9681f4befd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to unet3d_test_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: ëª¨ë¸ ì €ì¥\n",
    "save_path = \"unet3d_test_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"âœ… Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a15cabf0-8c42-468e-a4a6-865532a3694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì €ì¥ëœ í‚¤ ê°œìˆ˜: 70\n",
      "ì˜ˆì‹œ í‚¤: ['enc1.conv.weight', 'enc1.conv.bias', 'enc1.bn.weight', 'enc1.bn.bias', 'enc1.bn.running_mean']\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"unet3d_test_model.pt\", map_location='cpu')  # ë˜ëŠ” 'cuda'\n",
    "print(f\"ğŸ” ì €ì¥ëœ í‚¤ ê°œìˆ˜: {len(state_dict)}\")\n",
    "print(\"ì˜ˆì‹œ í‚¤:\", list(state_dict.keys())[:5])  # ì¼ë¶€ í‚¤ë§Œ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104f3a1-c157-40c1-9278-04a118be694d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
